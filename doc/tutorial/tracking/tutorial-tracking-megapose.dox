/**

\page tutorial-tracking-megapose Tutorial: Tracking with Megapose
\tableofcontents

\section megapose_tracking_intro Introduction

In this tutorial, we will explore how to use Megapose \cite Labbe2022Megapose, a deep learning method for object pose estimation.

Given:
  - An RGB or RGB-D image for which the intrinsics of the camera \f$c\f$ are known
  - A coarse detection of the image region in which lies the object
  - A 3D model of the object \f$o\f$
Megapose can estimate the pose of the object relative to the camera frame \f$^{c}\mathbf{T}_{o}\f$.

The method has several advantages:
  - Robust estimation in the presence of occlusions and lighting artifacts
  - Can work with a coarse model of the object
  - Does not require retraining for novel objects

It has however, several drawbacks:
  - Running megapose requires a GPU. However, the integration in ViSP is based on a client-server model: megapose can thus run on a remote machine and its result retrieved on the local host (e.g, a robot with a CPU)
  - It may be too slow for your requirements
    - With the default parameters, on a 640 x 480 image, Initial pose estimation takes around 2 seconds on an Nvidia Quadro RTX 6000
    - On the same setup, a pose update (refinement) iteration takes around 60-70 milliseconds
  - To perform the initial pose estimation, megapose requires an estimate of the image region containing the image (i.e., a bounding box detection).
    You may thus require a way to detect the object, such as an object detection neural network (available in ViSP with the class vpDetectorDNNOpenCV, see \ref tutorial-detection-dnn).
    For initial test, the bounding box can also be provided by the user via click.


The megapose integration in ViSP is based on a client-server model:
- The client, that uses either vpMegaPose or vpMegaPoseTracker, is C++-based. It sends pose estimation requests to the server.
- The server is written in Python. It wraps around the Megapose model. Each time a pose estimation is requested, the server reshapes the data and forwards it to Megapose. it then sends back the information to the client.

This tutorial will explain how to install and run megapose and
then demonstrate its usage with a simple object tracking application.


\section megapose_install Installation

\subsection megapose_cpp_install Installing the client

The megapose client, written in C++, is included directly in ViSP. To be installed and compiled, it requires:
- That ViSP be compiled with the JSON third-party library, as JSON is used to pass messages. To install the 3rd party, see the procedure for your system, e.g. \ref install_ubuntu_3rdparty_other for Ubuntu.
- ViSP should be compiled with the visp_dnn_tracker module. When generating build files with CMake, it will be built by default if the JSON third-party is detected on your system
  - To check that it is installed, you can check the `ViSP-third-party.txt` file that is generated by CMake:
  \code{.sh}
    ~/visp_build $ cat ViSP-third-party.txt | grep "To be built"
    To be built: core dnn_tracker gui imgproc io java_bindings_generator klt me sensor ar blob robot visual_features vs vision detection mbt tt tt_mi
  \endcode
  If "dnn_tracker" is in the list, then the client can be compiled and used.


To install the Megapose server, there are two dependencies:
  - Conda: Megapose will be installed in a new virtual environment in order to avoid potential conflicts with python and other packages you have already installed
    - To install conda on your system, we recommend `miniconda`, a minimal version of conda. To install, see <a href="https://docs.conda.io/en/latest/miniconda.html">the miniconda documentation</a>
    - Once installed, make sure that conda is in your environment path variable. The conda installation procedure should do this by default.
    - To check, simply enter `conda --version` in your terminal.
    - You should obtain an output similar to:
      \verbatim
      ~/visp_build$ conda --version
      conda 23.3.1
      \endverbatim
  - Git is also required in order to fetch the Megapose sources.
  If you built ViSP from sources, then it should already be installed.

The server sources are located in the `script/megapose_server` folder of your ViSP <br>source</br> directory

In this folder, you can find multiple files:
- `run.py`: the code for the server
- `install.py`: the installation script
- `megapose_variables.json`: configuration variables, used in the installation process

To start the installation process, you should first set the variables in `megapose_variables.json`:
- `environment`: name of the conda environment that will be created. The megapose server will be installed in this environment and it should thus be activated before trying to start the server.
  For example, if you set this variable to "visp_megapose_server", then you can activate it with: \code conda activate visp_megapose_server \endcode
- `megapose_dir`: the folder where megapose will be installed
- `megapose_data_dir`: the folder where the megapose deep learning models will be downloaded.


Once you have configured these variables: run the installation script with:
\code{.sh}
~/visp/script/megapose_server $ python install.py
\endcode

The script may run for a few minutes, as it downloads all the dependencies as well as the deep learning models that Megapose requires.

Once the script has finished, you can check the installation status with:
\code{.sh}
$ conda activate name_of_your_environment
$ python -m megapose_server.run -h
\endcode

The `-h` argument should print some documentation on the arguments that can be passed to the server.

With Megapose installed, you are now ready to run a basic, single object tracking example.

\section megapose_run Single object tracking with Megapose

In this tutorial, we will track an object from a live camera feed. For megapose to work, we will need:
- The 3D model of the object
- A way to detect the object in the image

\subsection megapose_start_server Starting the server

\subsection megapose_run_command Running the tracking example
\include megapose_cube.json


\subsection megapose_code Understanding the program

\snippet tutorial-megapose-live-single-object-tracking.cpp Instantiate megapose

\snippet tutorial-megapose-live-single-object-tracking.cpp Check megapose

\snippet tutorial-megapose-live-single-object-tracking.cpp Call megapose

\snippet tutorial-megapose-live-single-object-tracking.cpp Detect



The full code can be found at the end of the tutorial, or at tutorial-megapose-live-single-object-tracking.cpp


\subsection megapose_adaptation Adapting this tutorial for your use case



\include tutorial-megapose-live-single-object-tracking.cpp


*/
