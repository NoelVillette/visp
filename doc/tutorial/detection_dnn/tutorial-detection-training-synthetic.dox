/**

\page tutorial-detection-dnn-training-synthetic Tutorial: Training a detection network from a CAD model with Blenderproc
\tableofcontents

\section dnn_synthetic_intro Introduction

In this tutorial, we will show how to train a baseline detection neural network from a 3D model, thanks to blenderproc.

Most of the (manual) work when training a neural network resides in acquiring and labelling data. This process can be slow, tedious and error prone.
A solution to avoid this step is to use synthetic data, generated by a simulator/computer program. This approach comes with multiple advantages:
- Data acquisition is fast
- It is easy to acquire accurate ground truth labels
- Variations in the training data can be easily added

There are however, some drawbacks:
- More knowledge of the scene is required: in the case of detection, we require a 3D model of the object, which is not the case for true images
- A gap between simulated and real data can be apparent and negatively impact network performance (this is the Sim2Real gap)

The latter point is heavily dependent on the quality of the generated images and the more realistic the images, the better the expected results.

Blender, using ray tracing, can generate realistic images. To perform data generation, <a href="https://github.com/DLR-RM/BlenderProc">Blenderproc</a> has been developed and is an extremely useful and flexible tool to generate realistic scenes from Python.

In this tutorial, we will install blenderproc and use it to generate various simple but varied scenes containing an object of interest. We will then be able to train a YoloV7 with this data, for later use on real data.


\section dnn_synthetic_install Requirements


\section dnn_synthetic_next Next steps


*/
